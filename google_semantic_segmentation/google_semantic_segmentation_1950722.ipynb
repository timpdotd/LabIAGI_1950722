{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZbXC75AsRb1"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ldUXk7pfr2B"
      },
      "source": [
        "# Semantic Segmentation on Google images\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ7sN1iffO2V"
      },
      "source": [
        "## WORKFLOW\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oCCuFHzYKC5"
      },
      "source": [
        "- Analyze data - Exploratory Data Analysis (EDA)\n",
        "  - Regression of Classification?\n",
        "  - What is the target variable?\n",
        "  - Is the data unbalanced?\n",
        "  -  What are the features? Correlation, ranges, variances, values, NaN, errors...\n",
        "  - Plot to make findings clearer\n",
        "- Define the relevant metrics to be used\n",
        "- Train a first baseline algorithm as a reference, e.g.:\n",
        "  - For regression, train a model with all the features\n",
        "  - For classification test basic models as the one-class-classifier (always the same class) and the basic\n",
        "  logistic regression with all the features\n",
        "  - If there is already a State of the Art solution, use it as an additional baseline\n",
        "- Prepare data (where needed):\n",
        "  - cleaning (e.g. remove NaN, outliers, ...)\n",
        "  - normalization\n",
        "  - shuffling and train, test and validation set construction\n",
        "    - check the statistical properties of the splits\n",
        "- Design experiments and define hyperparameters\n",
        "- Repeat until performance on the test set is acceptable:\n",
        "  - Train model and cross validate hyper parameters until acceptable performance on training set is\n",
        "  achieved\n",
        "  - Test best hyper parameter model and check if there is overfitting or underfitting\n",
        "- Final Evaluation: ablation studies and failure modes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joxFRYUvfQgF"
      },
      "source": [
        "## Description"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The image segmentation task as the objective to identify the objective in a generic photo. This could be a multi-class or binary image segmentation: the first need to identify all the objectives in a photo, for example, the cat, the human, the table and so on; the second one need only to identify the object and what is not the object, for example the cat and the other things are \"not the cat\".\n",
        "\n",
        "In this notebook we will explore the image segmentation on photovoltaic panels in multi spectral satellitar images. We will use a UNET model for the task (see later on) and compare the results to identify the best outcomes and the difference between the prediction and the truth label."
      ],
      "metadata": {
        "id": "8T10cz1S_ALl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS7gRVCQOBFz"
      },
      "source": [
        "##Summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36vlp-rmlhzt"
      },
      "source": [
        "Photovoltaic (PV) energy generation plays a crucial role in the energy transition. Small-scale, residential PV installations are deployed at an unprecedented pace, and their safe integration into the grid necessitates up-to-date, high-quality information. Overhead imagery is increasingly used to improve the knowledge of residential PV installations with machine learning models capable of automatically mapping these installations. However, these models cannot be reliably transferred from one region or imagery source to another without incurring a decrease in accuracy. To address this issue, known as distribution shift, and foster the development of PV array mapping pipelines, we propose a dataset containing aerial images, segmentation masks, and installation metadata. We provide installation metadata for more than 28000 installations. We provide ground truth segmentation masks for 13000 installations, including 7000 with annotations for two different image providers. Finally, we provide installation metadata that matches the annotation for more than 8000 installations. Dataset applications include end-to-end PV registry construction, robust PV installations mapping, and analysis of crowdsourced datasets.\n",
        "\n",
        "This dataset contains the complete records associated with the article \"A crowdsourced dataset of aerial images of solar panels, their segmentation masks, and characteristics\", published in Scientific data. The article is accessible here : https://www.nature.com/articles/s41597-023-01951-4\n",
        "\n",
        "These complete records consist of:\n",
        "\n",
        "1. The complete training dataset containing RGB overhead imagery, segmentation masks and metadata of PV installations (folder bdappv),\n",
        "2. The raw crowdsourcing data, and the postprocessed data for replication and validation (folder data).\n",
        "---\n",
        "The description above is copied from the official page of the dataset.\n",
        "\n",
        "The dataset can be found here: https://zenodo.org/records/7358126\n",
        "\n",
        "The paper can be found here: https://www.nature.com/articles/s41597-023-01951-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSVRV8z3N8te"
      },
      "source": [
        "# About the dataset\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLWNgC5Ijli6"
      },
      "source": [
        "### bdappv/ Root data folder\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcy6C8g3rxK_"
      },
      "source": [
        "- google/ign:  One folder for each campaign\n",
        "  - img/: Folder containing all the images presented to the users. This folder contains 28807 images for Google and 17325 images for IGN.\n",
        "  - mask/: Folder containing all segmentations masks generated from the polygon annotations of the users. This folder contains 13303 masks for Google and 7686 masks for IGN.\n",
        "- metadata.csv The .csv  file with the installations' metadata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzN506ACjpDM"
      },
      "source": [
        "\n",
        "### data/ Root data folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7MmVatcr09K"
      },
      "source": [
        "- raw/ Folder containing the raw crowdsourcing data and raw metadata;\n",
        "  - input-google.json: .json input data data containing all information on images and raw annotators’ contributions for both phases (clicks and polygons) during the first annotation campaign;\n",
        "  - input-ign.json: .json input data containing all information on images and raw annotators’ contributions for both phases (clicks and polygons) during the second annotation campaign;\n",
        "  - raw-metadata.json: .json output containing the PV systems’ metadata extracted from the BDPV database before filtering. It can be used to replicate the association between the installations and the segmentation masks, as done in the notebook metadata.\n",
        "- replication/ Folder containing the compiled data used to generate the segmentation masks;\n",
        "  - campaign-google/campaign-ign: One folder for each campaign\n",
        "    - click-analysis.json: .json output on the click analysis, compiling raw input into a few best-guess locations for the PV arrays. This dataset enables the replication of our annotations,\n",
        "    - polygon-analysis.json: .json output of polygon analysis, compiling raw input into a best-guess polygon for the PV arrays.\n",
        "- validation/ Folder containing the compiled data used for technical validation.\n",
        "  - campaign-google/campaign-ign: One folder for each campaign\n",
        "    - click-analysis-thres=1.0.json: .json output of the click analysis with a lowered threshold to analyze the effect of the threshold on image classification, as done in the notebook annotation;\n",
        "    - polygon-analysis-thres=1.0.json: .json output of polygon analysis, with a lowered threshold to analyze the effect of the threshold on polygon annotation, as done in the notebook annotations.\n",
        "  - metadata.csv: the .csv file of filtered installations' metadata."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-5fo4iplI3v"
      },
      "source": [
        "# Import libraries & mounting Drive\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUoh0s3sftAs"
      },
      "source": [
        "### Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "Fnhj4qhzfvUU",
        "outputId": "140339ee-9348-4b39-983c-27afe7db2209"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-38e33c1ef003>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mount Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDztWb2rHhI1"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVIFFFYmHjqt"
      },
      "outputs": [],
      "source": [
        "# Plotting\n",
        "%matplotlib inline\n",
        "%reload_ext tensorboard\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.optim as optim\n",
        "import albumentations as A\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, ConcatDataset, TensorDataset, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Utilites\n",
        "import zipfile\n",
        "import os\n",
        "import requests\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "from shutil import copyfile\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install --quiet pytorch-lightning>=1.5\n",
        "    import pytorch_lightning as pl\n",
        "\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "# Wget\n",
        "try:\n",
        "    import wget\n",
        "except ModuleNotFoundError: # Google Colab does not have wget installed by default. Hence, we do it here if necessary\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xtWT8LA4VXd"
      },
      "source": [
        "## Constant values and useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt3mM2ux4YOc"
      },
      "outputs": [],
      "source": [
        "CAMPAIGN = \"/google\"\n",
        "\n",
        "# The answer to anything\n",
        "SEED = 42\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# URLS where you can find the dataset\n",
        "BDAPPV_URL = 'https://zenodo.org/records/7358126/files/bdappv.zip?download=1'\n",
        "DATA_URL = 'https://zenodo.org/records/7358126/files/data.zip?download=1'\n",
        "\n",
        "URLS = [DATA_URL, BDAPPV_URL]\n",
        "\n",
        "# Change this to save and extract files in different directories\n",
        "SAVE_DIR = '/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/dataset'\n",
        "EXTRACT_DIR = '/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/dataset'\n",
        "IMG_DIR = '/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/dataset/bdappv/google/img'\n",
        "MASK_DIR = '/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/dataset/bdappv/google/mask'\n",
        "\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 3\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 100\n",
        "IMAGE_WIDTH = 100 # Original: 400 x 400\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "TRAIN_IMG_DIR = \"/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/train/img\"\n",
        "TRAIN_MASK_DIR = \"/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/train/mask\"\n",
        "VAL_IMG_DIR = \"/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/validation/img\"\n",
        "VAL_MASK_DIR = \"/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/validation/mask\"\n",
        "TEST_IMG_DIR = '/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/test/img'\n",
        "TEST_MASK_DIR = '/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/test/mask'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGaROpdOxpJp"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnvWISoHtpQL"
      },
      "source": [
        "# Loading the dataset\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t45oh0q8mu61"
      },
      "source": [
        "In this section we will donwload all the folders needed from Zenodo (see [this section](https://colab.research.google.com/drive/1gi1CXB-m2aPufYSTBiFgnRidXj9tvEmy?authuser=3#scrollTo=36vlp-rmlhzt)). Where we will donwload it? On your Google Drive. All this process will be done only once. Make sure to have a stable Internet connection because it will take a while."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNGIZiH-rrkd"
      },
      "source": [
        "## Dowload and extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3phllz1Jph-5"
      },
      "source": [
        "In this section we will create the parent directory where we will store all the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmndGKHuwsQT"
      },
      "outputs": [],
      "source": [
        "parent_dir = '/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation'\n",
        "\n",
        "# Check if the parent directory exists, if not create it\n",
        "if not os.path.exists(parent_dir):\n",
        "    os.makedirs(parent_dir)\n",
        "\n",
        "# Copy the current notebook to the parent directory\n",
        "current_notebook = \"google_semantic_segmentation_1950722.ipynb\"\n",
        "destination_notebook = os.path.join(parent_dir, current_notebook)\n",
        "\n",
        "# Check if the notebook already exists in the parent directory, if not, copy it\n",
        "if not os.path.exists(destination_notebook):\n",
        "    copyfile(current_notebook, destination_notebook)\n",
        "\n",
        "# Define the path for the dataset directory\n",
        "dataset_dir = os.path.join(parent_dir, \"dataset\")\n",
        "\n",
        "# Check if the dataset directory exists, if not create it\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNefBJobwMwR"
      },
      "source": [
        "Here we donwload and extract the from the given url to our provided directory. To donwload the dataset change the variable `want_to_download`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaOdcxHpgNyF"
      },
      "outputs": [],
      "source": [
        "def download_and_extract(url, save_dir, extract_dir):\n",
        "    # Get the filename from the URL\n",
        "    filename = url.split('/')[-1]\n",
        "\n",
        "    # Check if the file already exists\n",
        "    if not os.path.exists(os.path.join(save_dir, filename)):\n",
        "        # Download and extract the zip file\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            with open(os.path.join(save_dir, filename), 'wb') as f:\n",
        "                shutil.copyfileobj(r.raw, f)\n",
        "\n",
        "        with zipfile.ZipFile(os.path.join(save_dir, filename), 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "\n",
        "        # Delete the zip file\n",
        "        os.remove(os.path.join(save_dir, filename))\n",
        "    else:\n",
        "        print(f\"Skipping installation of {filename}. File already exists.\")\n",
        "\n",
        "# Download and extract data from each URL\n",
        "want_to_download = False # Change this to True to download the dataset\n",
        "if want_to_download:\n",
        "    print(\"Downloading the dataset... (this will take a while)\")\n",
        "    for url in URLS:\n",
        "        print(f\"Downloading data from {url}\")\n",
        "        download_and_extract(url, SAVE_DIR, EXTRACT_DIR)\n",
        "else:\n",
        "    print(f\"To download the dataset, change the variable want_to_download, now setted to {want_to_download}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnc8QCv34wtA"
      },
      "source": [
        "## Checking files in each directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t39IY2wjgR-G"
      },
      "source": [
        "The following code count every file in every subdirectory of the given directory (in this case, where we extract the data).\n",
        "Check the number of files yourself:\n",
        "- dataset: 0\n",
        "    - dataset/data: 0\n",
        "        - dataset/data/raw: 3\n",
        "        - dataset/data/replication: 0\n",
        "            - dataset/data/replication/campaign-google: 2\n",
        "            - dataset/data/replication/campaign-ign: 2\n",
        "        - dataset/data/validation: 1\n",
        "            - dataset/data/validation/campaign-google: 2\n",
        "            - dataset/data/validation/campaign-ign: 2\n",
        "    - dataset/bdappv: 2\n",
        "        - dataset/bdappv/google: 0\n",
        "            - dataset/bdappv/google/img: 28807\n",
        "            - dataset/bdappv/google/mask: 13303\n",
        "        - dataset/bdappv/ign: 0\n",
        "            - dataset/bdappv/ign/img: 17325\n",
        "            - dataset/bdappv/ign/mask: 7685\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m6-4wBEKjFN"
      },
      "outputs": [],
      "source": [
        "# Function to explore directories and count files\n",
        "def explore_directories(directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        print(f\"Directory: {root}\")\n",
        "        print(f\"Number of files: {len(files)}\")\n",
        "        print(\"-------------------------------------\")\n",
        "\n",
        "# Explore directories and count files\n",
        "explore_directories(EXTRACT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtlA66l54mYy"
      },
      "source": [
        "# Processing the images\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGnaqfiT4N9Q"
      },
      "source": [
        "Not all the images are interesenting and some images missing the labels. In this section we will make sure to have all the images ready."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldm8WzqA4eIj"
      },
      "source": [
        "## Filtering by size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg5euSH54eIq"
      },
      "source": [
        "Not all the images are actually interesting for the purpose and many of them (177) haven't any information in them, so we will delete it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv6S3RDM7OMO"
      },
      "outputs": [],
      "source": [
        "small_images = []\n",
        "\n",
        "for image_file in os.listdir(IMG_DIR):\n",
        "    image_path = os.path.join(IMG_DIR, image_file)\n",
        "    mask_path = os.path.join(MASK_DIR, image_file)\n",
        "\n",
        "    # Check if image size is less than 10kb (10240 bytes)\n",
        "    if os.path.isfile(image_path) and os.path.getsize(image_path) < 10240:\n",
        "        small_images.append(image_file)\n",
        "        os.remove(image_path)\n",
        "\n",
        "print(f\"Deleted {len(small_images)} images that weights less than 10kB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dki8vpC2gzht"
      },
      "source": [
        "## Adding masks for images without it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JU47wAh-g5uQ"
      },
      "source": [
        "Many images are without label (almost 15 000). So with this code, if a image doens't have a mask, we will create a black label (label of all zeros) with the same name as the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPyQymA52UGZ"
      },
      "outputs": [],
      "source": [
        "images_without_masks = []\n",
        "\n",
        "for image_file in os.listdir(IMG_DIR):\n",
        "    image_path = os.path.join(IMG_DIR, image_file)\n",
        "    mask_path = os.path.join(MASK_DIR, image_file)\n",
        "    mask_name = os.path.splitext(image_file)[0] + \".png\"\n",
        "\n",
        "    # Check if mask exists (else create an empty label)\n",
        "    if not os.path.isfile(mask_path):\n",
        "        images_without_masks.append(image_file)\n",
        "        image = Image.open(image_path)\n",
        "        mask = Image.new(\"RGB\", image.size, color=\"black\")\n",
        "        mask.save(mask_path)\n",
        "\n",
        "print(f\"Added {len(images_without_masks)} empty labels for images without masks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naPzMWJsrrxQ"
      },
      "source": [
        "## Check if the numbers matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDpxSlpSrIMJ"
      },
      "source": [
        "Now check here if the images in the image directory and in the mask directory are the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgfzRHiFrHrc"
      },
      "outputs": [],
      "source": [
        "img_files = os.listdir(IMG_DIR)\n",
        "mask_files = os.listdir(MASK_DIR)\n",
        "\n",
        "assert len(img_files) == len(mask_files), \"Number of images and masks must be equal\"\n",
        "assert os.path.isdir(IMG_DIR), \"Image directory does not exist\"\n",
        "assert os.path.isdir(MASK_DIR), \"Mask directory does not exist\"\n",
        "\n",
        "print(f\"You have {len(img_files)} images and {len(mask_files)} masks\")\n",
        "print(f\"Image directory: {IMG_DIR}\")\n",
        "print(f\"Mask directory: {MASK_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI7vUGPP4Gv7"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfySqUw84Gv8"
      },
      "source": [
        "TODO: insert description of the section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r815YNx3sxA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/LabIAGI_1950722/google_semantic_segmentation/dataset/bdappv/metadata.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFKfgfV-4Gv8"
      },
      "source": [
        "## section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgchnSGF4Gv8"
      },
      "source": [
        "TODO: inserti description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMsyOXts8QEx"
      },
      "outputs": [],
      "source": [
        "google_count = (df['GoogleControlled'] == True).sum()\n",
        "ign_count = (df['IGNControlled'] == True).sum()\n",
        "unknown_count = ((df['GoogleControlled'] == False) & (df['IGNControlled'] == False)).sum()\n",
        "\n",
        "# Create bar plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(['Google', 'IGN', 'Unknown'], [google_count, ign_count, unknown_count], color=['blue', 'green', 'orange'])\n",
        "plt.xlabel('Source')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Number of Images Controlled by Source')\n",
        "\n",
        "# Create pie chart\n",
        "plt.subplot(1, 2, 2)\n",
        "labels = ['Google', 'IGN', 'Unknown']\n",
        "sizes = [google_count, ign_count, unknown_count]\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=['blue', 'green', 'orange'])\n",
        "plt.title('Percentage of Images Controlled by Source')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn0QKhID7nee"
      },
      "source": [
        "## Plot some samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRbribC99Bd_"
      },
      "source": [
        "TODO: fix this basend on the constat value in the beginning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZARhxJA7m5B"
      },
      "outputs": [],
      "source": [
        "img_files = [file for file in os.listdir(IMG_DIR) if file.endswith(('jpg', 'jpeg', 'png', 'bmp'))]\n",
        "random_image_files = random.sample(img_files, 5)\n",
        "set_seed(SEED)\n",
        "\n",
        "plt.figure(figsize=(10, 15))\n",
        "for i, random_image_file in enumerate(random_image_files, 1):\n",
        "    # Get the image\n",
        "    img_path = os.path.join(IMG_DIR, random_image_file)\n",
        "    img = Image.open(img_path).convert('RGBA')\n",
        "\n",
        "    # Get the mask\n",
        "    mask_path = os.path.join(MASK_DIR, random_image_file)\n",
        "    mask = Image.open(mask_path).convert('RGBA')\n",
        "\n",
        "    # Create an overlay\n",
        "    overlay = Image.blend(img, mask, alpha=0.7)\n",
        "\n",
        "    # Set the position of each image\n",
        "    plt.subplot(5, 3, 3*i-2)\n",
        "    plt.imshow(img)\n",
        "    plt.title('Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(5, 3, 3*i-1)\n",
        "    plt.imshow(mask)\n",
        "    plt.title('Mask')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(5, 3, 3*i)\n",
        "    plt.imshow(overlay)\n",
        "    plt.title('Overlay')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZSxOunVs3G5"
      },
      "source": [
        "# Splitting the dataset\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DajuVJt_s3G6"
      },
      "source": [
        "TODO: insert description of the section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi6jGdeTs3G6"
      },
      "source": [
        "## Splitting images into train, validation and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4MANkvDs3G6"
      },
      "source": [
        "TODO: inserti description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fceHij8XwW11"
      },
      "outputs": [],
      "source": [
        "# Shuffle the list of image files\n",
        "random.shuffle(img_files)\n",
        "set_seed(SEED)\n",
        "\n",
        "# Calculate the sizes of train, validation, and test sets\n",
        "num_images = len(img_files)\n",
        "train_size = int(0.6 * num_images)  # 60% for training\n",
        "val_size = int(0.2 * num_images)    # 20% for validation\n",
        "test_size = num_images - train_size - val_size  # Remaining for testing\n",
        "\n",
        "train_files = img_files[:train_size]\n",
        "val_files = img_files[train_size:train_size + val_size]\n",
        "test_files = img_files[train_size + val_size:]\n",
        "\n",
        "# Print the number of images in each set\n",
        "print(f\"Number of training images: {len(train_files)}\")\n",
        "print(f\"Number of validation images: {len(val_files)}\")\n",
        "print(f\"Number of testing images: {len(test_files)}\")\n",
        "print(f\"Total images: {len(train_files) + len(val_files) + len(test_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create new folders for the splitting"
      ],
      "metadata": {
        "id": "NwaDFHD12KC-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh9XMlZXebW9"
      },
      "source": [
        "Be careful: this operation may take long. Also, make sure to not have folders with the same name into your parent directory.\n",
        "\n",
        "This code makes three new directory and within each of them:\n",
        "- **a file txt** where all the images name are given for the plit\n",
        "- **img folder**, to store all the images in the given split\n",
        "- **mask folder**, to store all the images in the given split\n",
        "\n",
        "This operation is done only one time in your drive, then no more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdTQjlYQs3G6"
      },
      "outputs": [],
      "source": [
        "train_path = os.path.join(parent_dir, 'train')\n",
        "test_path = os.path.join(parent_dir, 'test')\n",
        "val_path = os.path.join(parent_dir, 'validation')\n",
        "\n",
        "files_paths = [\n",
        "    (train_path, train_files),\n",
        "    (test_path, test_files),\n",
        "    (val_path, val_files)\n",
        "]\n",
        "\n",
        "for directory, file_list in files_paths:\n",
        "    # Create main directory\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "    # Create subdirectories img and mask\n",
        "    img_directory = os.path.join(directory, 'img/')\n",
        "    mask_directory = os.path.join(directory, 'mask/')\n",
        "    os.makedirs(img_directory, exist_ok=True)\n",
        "    os.makedirs(mask_directory, exist_ok=True)\n",
        "\n",
        "    # Create file path\n",
        "    file_path = os.path.join(directory, f'{os.path.basename(directory)}.txt')\n",
        "\n",
        "    # Check if file already exists\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"Path to file already exists: {file_path}\")\n",
        "    else:\n",
        "        print(f\"Writing to file: {file_path}\")\n",
        "        content = []\n",
        "        for file_name in file_list:\n",
        "            image_path = os.path.join(IMG_DIR, file_name)\n",
        "            mask_path = os.path.join(MASK_DIR, file_name)\n",
        "            if os.path.exists(image_path) and os.path.exists(mask_path):\n",
        "                content.append(file_name)\n",
        "            else:\n",
        "                raise ValueError(\"Path don't exist\")\n",
        "\n",
        "        # Write content to file\n",
        "        with open(file_path, 'w') as file:\n",
        "            file.write('\\n'.join(content))\n",
        "\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "            for line in lines:\n",
        "                # Clean the line by removing leading and trailing whitespace and newline characters\n",
        "                cleaned_line = line.strip()\n",
        "\n",
        "                # Get the file paths for the image and mask\n",
        "                img_file_path = os.path.join(IMG_DIR, cleaned_line)\n",
        "                mask_file_path = os.path.join(MASK_DIR, cleaned_line)\n",
        "\n",
        "                # Check if the image and mask files exist and copy them in the new dir\n",
        "                if os.path.exists(img_file_path) and os.path.exists(mask_file_path):\n",
        "                    shutil.copy(img_file_path, os.path.join(img_directory, cleaned_line))\n",
        "                    shutil.copy(mask_file_path, os.path.join(mask_directory, cleaned_line))\n",
        "                else:\n",
        "                    print(f\"Image or mask file does not exist for {cleaned_line}\")\n",
        "\n",
        "\n",
        "        print(f\"Content for {file_path} written: {len(content)} lines\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sax2lPFebtx"
      },
      "source": [
        "Check every directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "explore_directories(train_path)"
      ],
      "metadata": {
        "id": "0BT44TzmtGnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explore_directories(test_path)"
      ],
      "metadata": {
        "id": "_nf7eJxFtJCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explore_directories(val_path)"
      ],
      "metadata": {
        "id": "gAjDa5qPtMN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then clean up some unusued memory"
      ],
      "metadata": {
        "id": "5jbqQapiF5gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del img_files\n",
        "del mask_files\n",
        "del num_images\n",
        "del train_size\n",
        "del val_size\n",
        "del test_size\n",
        "del train_files\n",
        "del val_files\n",
        "del test_files\n",
        "del files_paths"
      ],
      "metadata": {
        "id": "Bi4vsUJEkfIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class GoogleDataset"
      ],
      "metadata": {
        "id": "BxZjvcMJefeS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDrkGBOAejFO"
      },
      "source": [
        "TODO: inserti description"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogleDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(image_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.image_dir, self.images[index])\n",
        "        mask_path = os.path.join(self.image_dir, self.images[index])\n",
        "\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
        "\n",
        "        mask[mask == 255.0] = 1.0\n",
        "\n",
        "        if self.transform is not None:\n",
        "            augmentations = self.transform(image=image, mask=mask)\n",
        "            image = augmentations[\"image\"]\n",
        "            mask = augmentations[\"mask\"]\n",
        "\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "HNAIIDnnejXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeU_g2oDjMOM"
      },
      "source": [
        "# The model: U-Net\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ulgoy3PUjMON"
      },
      "source": [
        "TODO: insert description of the section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqM30h-S2fjU"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2_rLeSRjMON"
      },
      "source": [
        "## U-NET implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5TWr_K64AGE"
      },
      "source": [
        "TODO: inserti description"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNET(nn.Module):\n",
        "    def __init__(\n",
        "            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],\n",
        "    ):\n",
        "        super(UNET, self).__init__()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Down part of UNET\n",
        "        for feature in features:\n",
        "            self.downs.append(DoubleConv(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Up part of UNET\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(\n",
        "                nn.ConvTranspose2d(\n",
        "                    feature*2, feature, kernel_size=2, stride=2,\n",
        "                )\n",
        "            )\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[idx//2]\n",
        "\n",
        "            if x.shape != skip_connection.shape:\n",
        "                x = TF.resize(x, size=skip_connection.shape[2:])\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            x = self.ups[idx+1](concat_skip)\n",
        "\n",
        "        return self.final_conv(x)"
      ],
      "metadata": {
        "id": "kcmyjvFChaG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4c5mPht4AF8"
      },
      "source": [
        "## section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_gy9agNjMON"
      },
      "source": [
        "TODO: inserti description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRTELxvzLwNO"
      },
      "outputs": [],
      "source": [
        "model = UNET(in_channels=3, out_channels=1).to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In questo modo il learning rate viene moltiplicato di default per 0.1 dopo un terzo delle epoche e di novo a due terzi del training e aiuta a convergere su un risultato migliore, permettendo anche di usare un learning rate iniziale maggiore."
      ],
      "metadata": {
        "id": "IQf2V824jCP4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvDJDwgxvoXh"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "#optimizer_SGD = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "step_size = (NUM_EPOCHS // 3) + 1\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=step_size)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train UNET"
      ],
      "metadata": {
        "id": "5TM-BKVZuGtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZAUbsdyh4l2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_transform = A.Compose([\n",
        "    A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "    A.Normalize(\n",
        "        mean=[0.0, 0.0, 0.0],\n",
        "        std=[1.0, 1.0, 1.0],\n",
        "        max_pixel_value=255.0,\n",
        "    ),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "train_set = GoogleDataset(image_dir = TRAIN_IMG_DIR, mask_dir = TRAIN_MASK_DIR, transform = baseline_transform)\n",
        "val_set = GoogleDataset(image_dir = VAL_IMG_DIR, mask_dir = VAL_MASK_DIR, transform = baseline_transform)\n",
        "test_set = GoogleDataset(image_dir = TEST_IMG_DIR, mask_dir = TEST_MASK_DIR, transform = baseline_transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=False,)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=False,)"
      ],
      "metadata": {
        "id": "lsc5XYegxwa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "\n",
        "def get_loaders(\n",
        "    train_dir,\n",
        "    train_maskdir,\n",
        "    val_dir,\n",
        "    val_maskdir,\n",
        "    batch_size,\n",
        "    train_transform,\n",
        "    val_transform,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "):\n",
        "    train_ds = CarvanaDataset(\n",
        "        image_dir=train_dir,\n",
        "        mask_dir=train_maskdir,\n",
        "        transform=train_transform,\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    val_ds = CarvanaDataset(\n",
        "        image_dir=val_dir,\n",
        "        mask_dir=val_maskdir,\n",
        "        transform=val_transform,\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory,\n",
        "        shuffle=False,\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def check_accuracy(loader, model, device=\"cuda\"):\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device).unsqueeze(1)\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "            num_correct += (preds == y).sum()\n",
        "            num_pixels += torch.numel(preds)\n",
        "            dice_score += (2 * (preds * y).sum()) / (\n",
        "                (preds + y).sum() + 1e-8\n",
        "            )\n",
        "\n",
        "    print(\n",
        "        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n",
        "    )\n",
        "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
        "    model.train()\n",
        "\n",
        "def save_predictions_as_imgs(\n",
        "    loader, model, folder=\"saved_images/\", device=\"cuda\"\n",
        "):\n",
        "    model.eval()\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        x = x.to(device=device)\n",
        "        with torch.no_grad():\n",
        "            preds = torch.sigmoid(model(x))\n",
        "            preds = (preds > 0.5).float()\n",
        "        torchvision.utils.save_image(\n",
        "            preds, f\"{folder}/pred_{idx}.png\"\n",
        "        )\n",
        "        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "LEARNING_RATE = 1e-4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 3\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_HEIGHT = 160  # 1280 originally\n",
        "IMAGE_WIDTH = 240  # 1918 originally\n",
        "PIN_MEMORY = True\n",
        "LOAD_MODEL = False\n",
        "TRAIN_IMG_DIR = \"data/train_images/\"\n",
        "TRAIN_MASK_DIR = \"data/train_masks/\"\n",
        "VAL_IMG_DIR = \"data/val_images/\"\n",
        "VAL_MASK_DIR = \"data/val_masks/\"\n",
        "\n",
        "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
        "    loop = tqdm(loader)\n",
        "\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=DEVICE)\n",
        "        targets = targets.float().unsqueeze(1).to(device=DEVICE)\n",
        "\n",
        "        # forward\n",
        "        with torch.cuda.amp.autocast():\n",
        "            predictions = model(data)\n",
        "            loss = loss_fn(predictions, targets)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # update tqdm loop\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "\n",
        "def main():\n",
        "    train_transform = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Rotate(limit=35, p=1.0),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.VerticalFlip(p=0.1),\n",
        "            A.Normalize(\n",
        "                mean=[0.0, 0.0, 0.0],\n",
        "                std=[1.0, 1.0, 1.0],\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    val_transforms = A.Compose(\n",
        "        [\n",
        "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
        "            A.Normalize(\n",
        "                mean=[0.0, 0.0, 0.0],\n",
        "                std=[1.0, 1.0, 1.0],\n",
        "                max_pixel_value=255.0,\n",
        "            ),\n",
        "            ToTensorV2(),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    model = UNET(in_channels=3, out_channels=1).to(DEVICE)\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    train_loader, val_loader = get_loaders(\n",
        "        TRAIN_IMG_DIR,\n",
        "        TRAIN_MASK_DIR,\n",
        "        VAL_IMG_DIR,\n",
        "        VAL_MASK_DIR,\n",
        "        BATCH_SIZE,\n",
        "        train_transform,\n",
        "        val_transforms,\n",
        "        NUM_WORKERS,\n",
        "        PIN_MEMORY,\n",
        "    )\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model)\n",
        "\n",
        "\n",
        "    check_accuracy(val_loader, model, device=DEVICE)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
        "\n",
        "        # save model\n",
        "        checkpoint = {\n",
        "            \"state_dict\": model.state_dict(),\n",
        "            \"optimizer\":optimizer.state_dict(),\n",
        "        }\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "        # check accuracy\n",
        "        check_accuracy(val_loader, model, device=DEVICE)\n",
        "\n",
        "        # print some examples to a folder\n",
        "        save_predictions_as_imgs(\n",
        "            val_loader, model, folder=\"saved_images/\", device=DEVICE\n",
        "        )\n"
      ],
      "metadata": {
        "id": "X7Hg68dK4H9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "-3R575Eu4VJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fbplqd9jXq3"
      },
      "source": [
        "# The model: CHOOSE ANOTHER ONE\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpju_2V_jXq4"
      },
      "source": [
        "TODO: insert description of the section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crMQPfGhjXq6"
      },
      "source": [
        "## section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_b7w5ROjXq6"
      },
      "source": [
        "TODO: inserti description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7frFKGGZjY45"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vy9RP5Accfp"
      },
      "source": [
        "# Dump"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfk7-8ince95"
      },
      "source": [
        "\n",
        "\n",
        "Come modello puoi usare una semplice U-net (o altro modello a tua scelta). Un buon tutorial per implementare UNET è il seguente: https://www.youtube.com/watch?v=IHq1t7NxS8k&ab_channel=AladdinPersson.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "I training che dovrai eseguire sono almeno i seguenti:\n",
        "- Baseline (prova diversi learning rate su scala logaritmica, una volta individuato il migliore passa al punto successivo)\n",
        "- Aggiunta di data augmentation (almeno random horizontal/vertical flip, rotazioni di 0/90/180/270 gradi)\n",
        "- Per questo dataset è importante provare anche ad aggiungere RandomCrop. Questo perché i pannelli solari, se sono presenti, sono quasi sempre al centro dell'immagine, e potrebbe non generalizzare bene a un caso reale.\n",
        "\n",
        "Salvati tutti i training / pesi / grafici che fai, li vorrò vedere all'esame per vedere il lavoro fatto e le considerazioni che hai fatto.\n",
        "\n",
        "I modelli migliori (sul validation) usali sul test set e segnati i risultati in una tabela (IoU per ogni classe, mIoU e overall accuracy).\n",
        "\n",
        "Creati una repository GitHub dove puoi caricare di volta in volta il codice aggiornato. (Utile anche per dimostrare che il lavoro fatto è originale)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZSVRV8z3N8te",
        "nLWNgC5Ijli6",
        "uzN506ACjpDM",
        "O-5fo4iplI3v",
        "wnvWISoHtpQL",
        "UtlA66l54mYy",
        "5Fbplqd9jXq3",
        "_Vy9RP5Accfp"
      ],
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}